{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "colab": {
      "name": "Speaker Recognition.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.9.6 64-bit"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "interpreter": {
      "hash": "cf28b1cffad21296a8361ae6bbc573579d2c3478f41b644f350ce7a52ddb2396"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "source": [
        "import numpy as np\r\n",
        "import math\r\n",
        "from scipy.io.wavfile import read\r\n",
        "from scipy.signal import hamming\r\n",
        "from scipy.fftpack import fft, fftshift, dct"
      ],
      "outputs": [],
      "metadata": {
        "id": "mN1WhrYuBrqN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "source": [
        "train_dir = \"train\\\\\"\r\n",
        "test_dir = \"test\\\\\""
      ],
      "outputs": [],
      "metadata": {
        "id": "s-nGHKekCzOt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Feature Extraction"
      ],
      "metadata": {
        "id": "wQxFyFoeKSjF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "source": [
        "#calculate LPC coefficients from sound file\r\n",
        "\r\n",
        "def auto_correlation(x, lag):\r\n",
        "  n = len(x)\r\n",
        "  x_mean = np.mean(x)\r\n",
        "  y = x - x_mean\r\n",
        "  r = np.zeros((lag+1,1))\r\n",
        "  for k in range(lag+1):\r\n",
        "    top = 0\r\n",
        "    bottom = 0\r\n",
        "    for i in range(n-k):\r\n",
        "      top += y[i]*y[i+k]\r\n",
        "    for i in range(n):\r\n",
        "      bottom += y[i]*y[i]\r\n",
        "    if bottom==0:\r\n",
        "      r[k][0] = 0.0001\r\n",
        "    else:  \r\n",
        "      r[k][0] = top/bottom\r\n",
        "  return r\r\n",
        "\r\n",
        "\"\"\"Function to calculate symmetric matrix for matrix multiplication in further step to calculate alpha.\"\"\"\r\n",
        "\r\n",
        "def sym_matrix(n):\r\n",
        "  size = (n,n)\r\n",
        "  ret_mat = np.zeros(size)\r\n",
        "  for i in range(0,n):\r\n",
        "    for j in range(0,n):\r\n",
        "      ret_mat[i][j] = (np.abs(i-j))\r\n",
        "  \r\n",
        "  return ret_mat\r\n",
        "\r\n",
        "\"\"\"#Function to calculate Linear Prediction Coefficient.\"\"\"\r\n",
        "\r\n",
        "def lpc(signal, sampling_freq, no_coeff):\r\n",
        "  #print('Stage1: Time Framing')\r\n",
        "  \r\n",
        "  #Time Framing: Standard-25ms\r\n",
        "  no_sample = int(0.025*sampling_freq)\r\n",
        "  no_delay = int(0.010*sampling_freq)\r\n",
        "  no_frame = int(math.ceil(len(signal)/(no_sample-no_delay)))\r\n",
        "\r\n",
        "  #Padding\r\n",
        "  padding = ((no_sample - no_delay)*no_frame) - len(signal)\r\n",
        "  if padding > 0:\r\n",
        "    s = np.append(signal, np.zeros(padding))\r\n",
        "  else:\r\n",
        "    s = signal\r\n",
        "  #print('Stage1: Done')\r\n",
        "  \r\n",
        "  \r\n",
        "  #print('Stage2: Segmentation')\r\n",
        "  #segmenting signal in frames\r\n",
        "  start = 0\r\n",
        "  count = 0\r\n",
        "  for i in range(no_frame):\r\n",
        "    if start == 0:\r\n",
        "      seg_mat = np.zeros((1, no_sample))\r\n",
        "      seg_mat[0] = s[start:no_sample]\r\n",
        "      start = no_sample\r\n",
        "      count += 1\r\n",
        "    else:\r\n",
        "      if s.shape[0] - start >= 1200:\r\n",
        "        temp_mat = np.zeros((1, no_sample))\r\n",
        "        temp_mat[0][:] = s[start-no_delay:start-no_delay+no_sample]\r\n",
        "        start = start - no_delay + no_sample\r\n",
        "        seg_mat = np.vstack((seg_mat, temp_mat))\r\n",
        "        count += 1\r\n",
        "  #print('Stage2: Done')\r\n",
        "  #Hamming Window operation (Optional)\r\n",
        "  x = np.zeros_like(seg_mat)\r\n",
        "  for i in range(count):\r\n",
        "    x = seg_mat[i]*np.hamming(no_sample)\r\n",
        "\r\n",
        "  #print('Stage3: LPC with Yule-walker algorithm')\r\n",
        "  #print('Please Wait')\r\n",
        "  #calculating LPC with Yule-walker algorithm\r\n",
        "  lpc_coeff = np.zeros((count, no_coeff))\r\n",
        "  for i in range(count):\r\n",
        "    r1 = auto_correlation(seg_mat[i], no_coeff)\r\n",
        "    temp = r1[1:][0]\r\n",
        "    r = np.resize(temp,(no_coeff,1))\r\n",
        "    r = (-1)*r\r\n",
        "    R = sym_matrix(no_coeff)\r\n",
        "    for j in range(no_coeff):\r\n",
        "      for k in range(no_coeff):\r\n",
        "        val = int(R[k][j])\r\n",
        "        R[k][j] = r1[val]\r\n",
        "    pro_mat = np.zeros((no_coeff,1))\r\n",
        "    pro_mat = np.dot(np.linalg.pinv(R),r)\r\n",
        "    lpc_coeff[i] = np.resize(pro_mat, (1, no_coeff)) \r\n",
        "    #Converting in the range -1 to +1\r\n",
        "    lpc_coeff[i] = lpc_coeff[i][:]/np.max(np.abs(lpc_coeff[i]))\r\n",
        "\r\n",
        "  #print('Stage3: Done')\r\n",
        "  return lpc_coeff"
      ],
      "outputs": [],
      "metadata": {
        "id": "8WPmy5c7B0-U"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "source": [
        "# calculate LPCC coefficients from LPC coefficients\r\n",
        "\r\n",
        "def normi(arr):\r\n",
        "    maxi = np.max(arr) \r\n",
        "    mini = np.min(arr)\r\n",
        "    diffr = maxi - mini\r\n",
        "    for i in range(len(arr[:, 0])):\r\n",
        "        for k in range(len(arr[0, :])):\r\n",
        "            arr[i][k] = (arr[i][k] - mini) / diffr\r\n",
        "    return arr\r\n",
        "\r\n",
        "def lpcc(s, fs, seq, order):\r\n",
        "\r\n",
        "    #divide into segments of 25 ms with overlap of 10ms\r\n",
        "    nSamples = np.int32(0.025*fs)\r\n",
        "    overlap = np.int32(0.01*fs)\r\n",
        "    nFrames = np.int32(np.ceil(len(s)/(nSamples-overlap)))\r\n",
        "\r\n",
        "    #zero padding to make signal length long enough to have nFrames\r\n",
        "    padding = ((nSamples-overlap)*nFrames) - len(s)\r\n",
        "    if padding > 0:\r\n",
        "        signal = np.append(s, np.zeros(padding))\r\n",
        "    else:\r\n",
        "        signal = s\r\n",
        "    segment = np.empty((nSamples, nFrames))\r\n",
        "    start = 0\r\n",
        "    for i in range(nFrames):\r\n",
        "        segment[:,i] = signal[start:start+nSamples]\r\n",
        "        start = (nSamples-overlap)*i\r\n",
        "\r\n",
        "    lpcc_coeffs = np.empty((order, nFrames))\r\n",
        "    for n in range(1, order + 1):\r\n",
        "        # Use order + 1 as upper bound for the last iteration\r\n",
        "        upbound = (order + 1 if n > order else n)\r\n",
        "        lpcc_coef = -sum(i * seq[:, n - i - 1] for i in range(1, upbound)) * 1. / upbound\r\n",
        "        lpcc_coef -= seq[:, n - 1] if n <= len(seq[:, n]) else 0\r\n",
        "        np.vstack((lpcc_coeffs[:, n], lpcc_coef))\r\n",
        "    lpcc_coeffs = np.nan_to_num(lpcc_coeffs)\r\n",
        "    lpcc_coeffs = np.float64(lpcc_coeffs)\r\n",
        "    lpcc_coeffs = normi(lpcc_coeffs)\r\n",
        "    \r\n",
        "    return lpcc_coeffs.T"
      ],
      "outputs": [],
      "metadata": {
        "id": "pcChQ0YSKKdL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "source": [
        "def hertz_to_mel(freq):\r\n",
        "    return 1125*np.log(1 + freq/700)\r\n",
        "    \r\n",
        "def mel_to_hertz(m):\r\n",
        "    return 700*(np.exp(m/1125) - 1)\r\n",
        "    \r\n",
        "#calculate mel frequency filter bank\r\n",
        "def mel_filterbank(nfft, nfiltbank, fs):\r\n",
        "     \r\n",
        "    #set limits of mel scale from 300Hz to 8000Hz\r\n",
        "    lower_mel = hertz_to_mel(300)\r\n",
        "    upper_mel = hertz_to_mel(8000)\r\n",
        "    mel = np.linspace(lower_mel, upper_mel, nfiltbank+2)\r\n",
        "    hertz = [mel_to_hertz(m) for m in mel]\r\n",
        "    fbins = [int(hz * int(nfft/2+1)/fs) for hz in hertz]\r\n",
        "    fbank = np.empty((int(nfft/2+1),nfiltbank))\r\n",
        "    for i in range(1,nfiltbank+1):\r\n",
        "        for k in range(int(nfft/2 + 1)):\r\n",
        "            if k < fbins[i-1]:\r\n",
        "                fbank[k, i-1] = 0\r\n",
        "            elif k >= fbins[i-1] and k < fbins[i]:\r\n",
        "                fbank[k,i-1] = (k - fbins[i-1])/(fbins[i] - fbins[i-1])\r\n",
        "            elif k >= fbins[i] and k <= fbins[i+1]:\r\n",
        "                fbank[k,i-1] = (fbins[i+1] - k)/(fbins[i+1] - fbins[i])\r\n",
        "            else:\r\n",
        "                fbank[k,i-1] = 0\r\n",
        "     \r\n",
        "#    plotting mel frequency filter banks           \r\n",
        "#    plt.figure(1)\r\n",
        "#    xbins = fs*np.arange(0,nfft/2+1)/(nfft/2+1)\r\n",
        "#    for i in range(nfiltbank):\r\n",
        "#        plt.plot(xbins, fbank[:,i])\r\n",
        "#    plt.axis(xmax = 8000)\r\n",
        "#    plt.xlabel('Frequency in Hz')\r\n",
        "#    plt.ylabel('Amplitude')\r\n",
        "#    plt.title('Mel Filterbank')\r\n",
        "#    plt.show()\r\n",
        "    return fbank\r\n",
        "            \r\n",
        "def mfcc(s,fs, nfiltbank):\r\n",
        "  \r\n",
        "    #divide into segments of 25 ms with overlap of 10ms\r\n",
        "    nSamples = np.int32(0.025*fs)\r\n",
        "    overlap = np.int32(0.01*fs)\r\n",
        "    nFrames = np.int32(np.ceil(len(s)/(nSamples-overlap)))\r\n",
        "    #zero padding to make signal length long enough to have nFrames\r\n",
        "    padding = ((nSamples-overlap)*nFrames) - len(s)\r\n",
        "    if padding > 0:\r\n",
        "        signal = np.append(s, np.zeros(padding))\r\n",
        "    else:\r\n",
        "        signal = s\r\n",
        "      \r\n",
        "    #segmenting signal in frames    \r\n",
        "    segment = np.empty((nSamples, nFrames))\r\n",
        "    start = 0\r\n",
        "    for i in range(nFrames):\r\n",
        "        segment[:,i] = signal[start:start+nSamples]\r\n",
        "        start = (nSamples-overlap)*i\r\n",
        "    \r\n",
        "    #compute periodogram\r\n",
        "    nfft = 512\r\n",
        "    periodogram = np.empty((nFrames, int(nfft/2 + 1)))\r\n",
        "    for i in range(nFrames):\r\n",
        "        x = segment[:,i] * hamming(nSamples)\r\n",
        "        spectrum = fftshift(fft(x,nfft))\r\n",
        "        periodogram[i,:] = abs(spectrum[int(nfft/2-1):])/nSamples\r\n",
        "        \r\n",
        "    #obtain filterbank  \r\n",
        "    fbank = mel_filterbank(nfft, nfiltbank, fs)\r\n",
        "    \r\n",
        "    #nfiltbank MFCCs for each frame\r\n",
        "    mel_coeff = np.empty((nfiltbank,nFrames))\r\n",
        "    for i in range(nfiltbank):\r\n",
        "        for k in range(nFrames):\r\n",
        "            mel_coeff[i,k] = np.sum(periodogram[k,:]*fbank[:,i])\r\n",
        "            \r\n",
        "    mel_coeff = np.log10(mel_coeff)\r\n",
        "    mel_coeff = dct(mel_coeff)\r\n",
        "    #exclude 0th order coefficient (much larger than others)\r\n",
        "    mel_coeff[0,:]= np.zeros(nFrames)\r\n",
        "    return mel_coeff.T"
      ],
      "outputs": [],
      "metadata": {
        "id": "HDd-VxLY8QLa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Feature Match"
      ],
      "metadata": {
        "id": "bVng905jKY3a"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "source": [
        "def EuclideanDistance(m1, m2):\r\n",
        "  \"\"\"Takes in two matrices as parameters (m1, m2)\r\n",
        "  and returns the Euclidean Distance Matrix between them\r\n",
        "  \"\"\"\r\n",
        "  \r\n",
        "  r = np.shape(m1)[0] # Number of rows in the Euclidean Distance Matrix will be number of rows in m1\r\n",
        "  c = np.shape(m2)[0] # Number of columns in the Euclidean Distance Matrix will be number of rows in m2\r\n",
        " \r\n",
        "  EDM = np.empty((r, c)) #Euclidean Distance Matrix EDM (empty) created\r\n",
        " \r\n",
        " \r\n",
        "  for i in range(r):\r\n",
        "    for j in range(c):\r\n",
        "      EDM[i][j] = math.sqrt(np.sum(np.square(np.subtract(m1[i], m2[j]))))\r\n",
        " \r\n",
        "  return EDM"
      ],
      "outputs": [],
      "metadata": {
        "id": "saX-6hsaCAGd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "VQ - LBG"
      ],
      "metadata": {
        "id": "sEZYk6gh5m5U"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "source": [
        "def lbg_codebook(fvs, M):\r\n",
        "  \"\"\"\r\n",
        "  Uses the LBG Algorithm to generate the codebook using the features\r\n",
        "  fvs are the feature vectors\r\n",
        "  M is the number of centroids\r\n",
        "  \"\"\"\r\n",
        "  \r\n",
        "  #INITIALIZATION\r\n",
        "  no_centroids = 1\r\n",
        "  centroid_coord = np.mean(fvs, axis = 0) #Centroid of features\r\n",
        "  r = no_centroids   #number of rows in codebook (initially)\r\n",
        "  c = len(centroid_coord)   #number of columns in codebook (initially)\r\n",
        "  codebook = np.empty((r,c))  #codebook created\r\n",
        "  codebook[0] = centroid_coord #first and only codevector will be the centroid of the given features\r\n",
        "\r\n",
        "  e = 0.01\r\n",
        "  \r\n",
        "  while no_centroids < M: \r\n",
        "    #DOUBLING THE CODEBOOK according to the formula y(n)+ = y(n)*(1+e) , y(n)- = y(n)*(1-e)\r\n",
        "    newcodebook = np.empty((2*r, c)) #Creating a temporary codebook that is to be updated\r\n",
        "\r\n",
        "    for i in range(no_centroids):\r\n",
        "      newcodebook[2*i] = codebook[i] * (1+e)    #y(n)+ = y(n)*(1+e)\r\n",
        "      newcodebook[2*i+1] = codebook[i] * (1-e)  #y(n)- = y(n)*(1-e)\r\n",
        "\r\n",
        "\r\n",
        "    codebook = newcodebook #codebook updated\r\n",
        "    r = np.shape(codebook)[0] #updating the value of centroid // again, the number of centroids = number of codewords\r\n",
        "    no_centroids = r #Again, the number of centroids is the number of rows\r\n",
        "  \r\n",
        "    Distance = EuclideanDistance(fvs, codebook) #Distance Matrix\r\n",
        "    distortion = 1\r\n",
        "    \r\n",
        "    while np.abs(distortion) > e: \r\n",
        "      #NEAREST NEIGHBOUR SEARCH\r\n",
        "      previousDistance = np.mean(Distance)\r\n",
        "      nearestcentroidID = np.argmin(Distance,axis = 1)  #Contains the indices of the closest codeword for each feature\r\n",
        " \r\n",
        "      #SET NEW CENTROID TO THE CENTROID OF ALL FEATURES CLOSE TO CENTROID i\r\n",
        "      for i in range(no_centroids):\r\n",
        "        codebook[i] = np.nan_to_num( np.nanmean(fvs[np.where(nearestcentroidID == i)], axis = 0) ) # THROWS RUN-TIME WARNING\r\n",
        "      \r\n",
        "      Distance = EuclideanDistance(fvs, codebook)\r\n",
        "      newDistance = np.mean(Distance)\r\n",
        "      distortion = (previousDistance - newDistance)/previousDistance  #updating distortion\r\n",
        "  return codebook "
      ],
      "outputs": [],
      "metadata": {
        "id": "u6aTCzE25pkf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Helper Functions"
      ],
      "metadata": {
        "id": "8ncBcajUKatq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "source": [
        "def closestSpeaker(spkr_features, all_features, fm_model_type):\r\n",
        "    minDistance = np.inf\r\n",
        "    for name in all_features:\r\n",
        "        if fm_model_type == 'LBG':\r\n",
        "            dist = EuclideanDistance(spkr_features, all_features[name])\r\n",
        "            Distance = np.sum(np.min(dist, axis = 1))/(np.shape(dist)[0])\r\n",
        "\r\n",
        "        if Distance < minDistance:\r\n",
        "            minDistance = Distance\r\n",
        "            speaker = name\r\n",
        "\r\n",
        "    return speaker"
      ],
      "outputs": [],
      "metadata": {
        "id": "qUEYX9dMNuY1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "source": [
        "def feature_extract(s, fs, model_type, orderLPC = 15, nfiltbank = 12):\r\n",
        "    if model_type == 'LPCC':\r\n",
        "        lpc_coeff = lpc(s, fs, orderLPC)\r\n",
        "        lpcc_coeff = lpcc(s, fs, lpc_coeff, orderLPC)\r\n",
        "        return lpcc_coeff\r\n",
        "    elif model_type == 'LPC':\r\n",
        "        lpc_coeff = lpc(s, fs, orderLPC)\r\n",
        "        return lpc_coeff\r\n",
        "    elif model_type == 'MFCC':\r\n",
        "        mfcc_coeff = mfcc(s, fs, nfiltbank)\r\n",
        "        return mfcc_coeff\r\n",
        "    else:\r\n",
        "        print(\"Invalid model type! Model type should be 'LPCC' or 'LPC' or 'MFCC'\")\r\n",
        "        exit()\r\n"
      ],
      "outputs": [],
      "metadata": {
        "id": "sBH_Ab7t53DH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "source": [
        "def feature_match(spkr_features, all_features, fm_model_type, no_centroids = 5):\r\n",
        "    if fm_model_type == 'LBG':\r\n",
        "        # CODEBOOK GENERATION FOR VQ-LBG\r\n",
        "        codebooks = {}\r\n",
        "        for name in all_features:\r\n",
        "            codebooks[name] = lbg_codebook(all_features[name], no_centroids) #features passed to lbg are the LPC/LPCC coefficients for current speaker.\r\n",
        "        foundname = closestSpeaker(spkr_features, codebooks, fm_model_type)\r\n",
        "    \r\n",
        "    elif fm_model_type == 'DTW':\r\n",
        "        foundname = closestSpeaker(spkr_features, all_features, fm_model_type)\r\n",
        "        \r\n",
        "    return foundname\r\n",
        "        "
      ],
      "outputs": [],
      "metadata": {
        "id": "bw2ZbAeh6ARk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "source": [
        "def train(fe_model_type, name, orderLPC, no_filtbank, no_centroids, train_dir):\r\n",
        "    directory = train_dir\r\n",
        "\r\n",
        "    fname = name + '.wav'\r\n",
        "    #print(\"Now\", name+\"\\'s features are being trained\")\r\n",
        "    (fs,s) = read(directory + fname) #for each file, read() returns a tuple. fs is samples/second (sample rate) and s is the actual signal data read from the audio file\r\n",
        "    features = feature_extract(s, fs, fe_model_type, orderLPC, no_filtbank)\r\n",
        "        \r\n",
        "    # print (\"Training for \" + name + \" complete.\\n\")\r\n",
        "\r\n",
        "    return features"
      ],
      "outputs": [],
      "metadata": {
        "id": "zGLhh2RGCCin"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Automatic Speaker Recognition"
      ],
      "metadata": {
        "id": "HhOcYUtOKg72"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "source": [
        "# HYPERPARAMETERS\r\n",
        "\r\n",
        "no_filtbank = 12\r\n",
        "orderLPC = 20\r\n",
        "no_centroids = 5\r\n",
        "fe_types = ['MFCC', 'LPC'] # Feautre Extraction model types - 'MFCC' | 'LPC'\r\n",
        "fm_types = ['LBG'] # Feature Match model types - 'LBG'"
      ],
      "outputs": [],
      "metadata": {
        "id": "4cxAtbD0_KvS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "source": [
        "names = []\r\n",
        "for i in range(8):\r\n",
        "    names.append('s'+str(i+1))\r\n",
        "\r\n",
        "no_crct = np.zeros((len(fe_types), len(fm_types)))\r\n",
        "\r\n",
        "for i in range(len(fe_types)):\r\n",
        "    for j in range(len(fm_types)):\r\n",
        "\r\n",
        "        train_features = {}\r\n",
        "        for name in names:\r\n",
        "            train_features[name] = train(fe_types[i], name, orderLPC, no_filtbank, no_centroids, train_dir)\r\n",
        "  \r\n",
        "        #COMPARISON\r\n",
        "        print(\"USING \"+fe_types[i]+\" and \"+fm_types[j]+\"\\n\")\r\n",
        "\r\n",
        "        # TEST\r\n",
        "        for name in names:\r\n",
        "            fname = name + '.wav' \r\n",
        "            # print('Now ', name+'\\'s test features are being tested')\r\n",
        "            (fs,s) = read(test_dir + fname)\r\n",
        "            curr_features = feature_extract(s, fs, fe_types[i], orderLPC, no_filtbank)\r\n",
        "            \r\n",
        "            foundname = feature_match(curr_features, train_features, fm_types[j], no_centroids)\r\n",
        "            \r\n",
        "            print(name+'.wav', ' in test matches with ', foundname+'.wav in train \\n')\r\n",
        "            if(name == foundname):\r\n",
        "                no_crct[i][j]+=1"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "USING MFCC and LBG\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "C:\\Users\\Thanmay\\AppData\\Local\\Temp/ipykernel_4600/356329028.py:41: RuntimeWarning: Mean of empty slice\n",
            "  codebook[i] = np.nan_to_num( np.nanmean(fvs[np.where(nearestcentroidID == i)], axis = 0) ) # THROWS RUN-TIME WARNING\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "s1.wav  in test matches with  s1.wav in train \n",
            "\n",
            "s2.wav  in test matches with  s2.wav in train \n",
            "\n",
            "s3.wav  in test matches with  s3.wav in train \n",
            "\n",
            "s4.wav  in test matches with  s4.wav in train \n",
            "\n",
            "s5.wav  in test matches with  s5.wav in train \n",
            "\n",
            "s6.wav  in test matches with  s6.wav in train \n",
            "\n",
            "s7.wav  in test matches with  s7.wav in train \n",
            "\n",
            "s8.wav  in test matches with  s8.wav in train \n",
            "\n",
            "USING LPC and LBG\n",
            "\n",
            "s1.wav  in test matches with  s1.wav in train \n",
            "\n",
            "s2.wav  in test matches with  s2.wav in train \n",
            "\n",
            "s3.wav  in test matches with  s3.wav in train \n",
            "\n",
            "s4.wav  in test matches with  s4.wav in train \n",
            "\n",
            "s5.wav  in test matches with  s5.wav in train \n",
            "\n",
            "s6.wav  in test matches with  s6.wav in train \n",
            "\n",
            "s7.wav  in test matches with  s7.wav in train \n",
            "\n",
            "s8.wav  in test matches with  s8.wav in train \n",
            "\n"
          ]
        }
      ],
      "metadata": {
        "id": "481Tu1zjDYcU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "241783d6-94e0-41cd-a896-c2cbfc0eae27"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Result"
      ],
      "metadata": {
        "id": "qGvYEF4yKjZa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "source": [
        "#RESULT\r\n",
        "print(\"RESULT\", end='')\r\n",
        "print(' ( Number of Speakers:', len(names), ')\\n')\r\n",
        "for i in range(len(fe_types)):\r\n",
        "    for j in range(len(fm_types)):\r\n",
        "        accuracy = np.round( (no_crct[i,j]/len(train_features.keys()))*100 , decimals = 3)\r\n",
        "        print(\"Accuracy (\" + fe_types[i] + \" + \" + fm_types[j] + \"): \",accuracy, \"%\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESULT ( Number of Speakers: 8 )\n",
            "\n",
            "Accuracy (MFCC + LBG):  100.0 %\n",
            "Accuracy (LPC + LBG):  100.0 %\n"
          ]
        }
      ],
      "metadata": {
        "id": "LKel37EeDa5-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5635a01c-c7f3-485a-9197-45d589298a75"
      }
    }
  ]
}